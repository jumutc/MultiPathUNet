{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biomedical Image Segmentation Pipeline\n",
    "\n",
    "## File structure setup\n",
    "\n",
    "First we are going to setup our filestructure in order to use the Image IO Interface.  \n",
    "What we want for the Image_interface is something like that:\n",
    "\n",
    "```\n",
    "data/\n",
    "     imgname001/imaging.png\n",
    "                segmentation.png\n",
    "     imgname002/imaging.png\n",
    "                segmentation.png\n",
    "     imgname003/imaging.png\n",
    "                segmentation.png\n",
    "     ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File structure preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(f'GPU device availability: {physical_devices}')\n",
    "\n",
    "# Configure data path for celltracking data set Fluo-N2DL-HeLa and file structure\n",
    "path_common = \"{define_your_path_to_images_here}\"\n",
    "path_ds_1 = os.path.join(path_common, \"Fluo-N2DL-HeLa\")\n",
    "path_ds_clean = os.path.join(path_common, \"clean_data\")\n",
    "\n",
    "img_type, img_format, seg_path = \"grayscale\", \"tif\", \"_ST\"\n",
    "image_formats = {\n",
    "    'tif': 'TIFF',\n",
    "    'jpg': 'JPEG'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize file structure\n",
    "if not os.path.exists(path_ds_clean): os.mkdir(path_ds_clean)\n",
    "\n",
    "# Iterate over both data sets\n",
    "for ds in [\"01\", \"02\"]:\n",
    "    # Define image directories\n",
    "    path_ds_img = os.path.join(path_ds_1, ds)\n",
    "    path_ds_seg = os.path.join(path_ds_1, ds + seg_path, \"SEG\")\n",
    "    # Obtain sample list\n",
    "    sample_list = os.listdir(path_ds_seg)\n",
    "    # Remove every file which does not match image type and preprocess sample names\n",
    "    for i in reversed(range(0, len(sample_list))):\n",
    "        if not sample_list[i].endswith(\".tif\"):\n",
    "            del sample_list[i]\n",
    "        else:\n",
    "            sample_list[i] = sample_list[i][7:]\n",
    "    # Iterate over each sample and transform the data into desired file structure\n",
    "    for sample in sample_list:\n",
    "        index = 'SAMPLE_' + ds + '_' + sample[:-4]\n",
    "        # Create sample directory\n",
    "        path_sampleDir = os.path.join(path_ds_clean, index)\n",
    "        if not os.path.exists(path_sampleDir): os.mkdir(path_sampleDir)\n",
    "        # Copy image file into filestructure\n",
    "        path_ds_sample_img = os.path.join(path_ds_img, \"t\" + sample)\n",
    "        path_fs_sample_img = os.path.join(path_sampleDir, f\"imaging.{img_format}\")\n",
    "        shutil.copy(path_ds_sample_img, path_fs_sample_img)  \n",
    "        # Copy segmentation file into filestructure\n",
    "        seg_file = \"man_seg\" + sample\n",
    "        path_ds_sample_seg = os.path.join(path_ds_seg, seg_file)\n",
    "        path_fs_sample_seg = os.path.join(path_sampleDir, f\"segmentation.{img_format}\")\n",
    "        # Load segmentation from file\n",
    "        seg_raw = Image.open(path_ds_sample_seg)\n",
    "        # Convert segmentation from Pillow image to numpy matrix\n",
    "        seg_pil = seg_raw.convert(\"LA\")\n",
    "        seg = np.array(seg_pil)\n",
    "        # Keep only intensity and remove maximum intensitiy range\n",
    "        seg_data = seg[:,:,0]\n",
    "        # Union all separate cell classes to a single one\n",
    "        seg_data[seg_data > 0] = 1\n",
    "        # Transform numpy array back to a Pillow image & save to disk\n",
    "        seg = Image.fromarray(seg_data)\n",
    "        seg.save(path_fs_sample_seg, format=image_formats[img_format])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary fix for problems in [MIScnn](https://github.com/frankkramer-lab/MIScnn/pull/91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miscnn.data_loading.interfaces import Image_interface\n",
    "\n",
    "class Fixed_Image_interface(Image_interface):\n",
    "    #---------------------------------------------#\n",
    "    #                  load_image                 #\n",
    "    #---------------------------------------------#\n",
    "    def load_image(self, index):\n",
    "        # Make sure that the image file exists in the data set directory\n",
    "        img_path = os.path.join(self.data_directory, index)\n",
    "        if not os.path.exists(img_path):\n",
    "            raise ValueError(\n",
    "                \"Sample could not be found \\\"{}\\\"\".format(img_path)\n",
    "            )\n",
    "        # Load image from file\n",
    "        img_raw = Image.open(os.path.join(img_path, \"imaging\" + \".\" + \\\n",
    "                                          self.img_format))\n",
    "        # Convert image to rgb or grayscale\n",
    "        if self.img_type == \"grayscale\" and len(img_raw.getbands()) > 1 :\n",
    "            img_pil = img_raw.convert(\"LA\")\n",
    "        elif self.img_type == \"rgb\" and img_raw.mode != \"RGB\":\n",
    "            img_pil = img_raw.convert(\"RGB\")\n",
    "        else:\n",
    "            img_pil = img_raw\n",
    "        \n",
    "        # Convert Pillow image to numpy matrix\n",
    "        img = np.array(img_pil)\n",
    "        # Keep only intensity for grayscale images\n",
    "        if self.img_type == \"grayscale\" and len(img.shape) > 2:\n",
    "            img = img[:, :, 0]\n",
    "        # Return image\n",
    "        return img, {\"type\": \"image\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image sample display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "from miscnn import Data_IO\n",
    "from miscnn.data_loading.interfaces import Image_interface\n",
    "\n",
    "# Initialize Data IO & Image Interface\n",
    "interface = Fixed_Image_interface(classes=2, img_type=img_type, img_format=img_format)\n",
    "data_io = Data_IO(interface, path_ds_clean, delete_batchDir=True)\n",
    "\n",
    "# Obtain the sample list\n",
    "sample_list = data_io.get_indiceslist()\n",
    "sample_list.sort()\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the first sample via MIScnn data loader\n",
    "sample_test = data_io.sample_loader(sample_list[0], load_seg=True)\n",
    "\n",
    "# Visualize the image\n",
    "img_data = sample_test.img_data\n",
    "print(\"Shape of image:\", img_data.shape)\n",
    "img = Image.fromarray(img_data[:,:,-1])\n",
    "display(img)\n",
    "\n",
    "# Visualize the ground truth segmentation\n",
    "seg_data = sample_test.seg_data * 100\n",
    "print(\"Shape of segmentation:\", seg_data.shape)\n",
    "seg = Image.fromarray(seg_data[:,:,-1])\n",
    "display(seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a custom architecture\n",
    "### Multi-Path U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Conv3DTranspose\n",
    "from tensorflow.keras.layers import Reshape, Dropout, LeakyReLU, Attention, LayerNormalization\n",
    "# Internal libraries/scripts\n",
    "from miscnn.neural_network.architecture.abstract_architecture import Abstract_Architecture\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#           Architecture class: U-Net Plain           #\n",
    "#-----------------------------------------------------#\n",
    "\"\"\" The Plain variant of the popular U-Net architecture.\n",
    "Methods:\n",
    "    __init__                Object creation function\n",
    "    create_model_2D:        Creating the 2D U-Net plain model using Keras\n",
    "    create_model_3D:        Creating the 3D U-Net plain model using Keras\n",
    "\"\"\"\n",
    "class UNetMultiPath(Abstract_Architecture):\n",
    "    #---------------------------------------------#\n",
    "    #                Initialization               #\n",
    "    #---------------------------------------------#\n",
    "    def __init__(self):\n",
    "        # Create list of filters\n",
    "        self.feature_maps = {\n",
    "            4: [40, 240],\n",
    "            2: [40, 80, 160, 220]\n",
    "        }\n",
    "\n",
    "    #---------------------------------------------#\n",
    "    #               Create 2D Model               #\n",
    "    #---------------------------------------------#\n",
    "    def create_model_2D(self, input_shape, n_labels=2):\n",
    "        # Input layer\n",
    "        inputs = Input(input_shape)\n",
    "        # Cache contracting normalized conv layers\n",
    "        # for later copy & concatenate links\n",
    "        contracting_convs = {c: [] for c in self.feature_maps.keys()}\n",
    "        all_middle_chains = []\n",
    "        all_chains = []\n",
    "        \n",
    "        for stride, feature_map in self.feature_maps.items():\n",
    "            # Start the CNN Model chain with adding the inputs as first tensor\n",
    "            cnn_chain = inputs\n",
    "\n",
    "            # Contracting layers\n",
    "            for i in range(0, len(feature_map)):\n",
    "                neurons = feature_map[i]\n",
    "                cnn_chain = conv_layer_2D(cnn_chain, neurons, strides=1)\n",
    "                cnn_chain = conv_layer_2D(cnn_chain, neurons, strides=1)\n",
    "                cnn_chain = SpatialDropout2D(0.5)(cnn_chain)\n",
    "                contracting_convs[stride].append(cnn_chain)\n",
    "                cnn_chain = MaxPooling2D(pool_size=(stride, stride))(cnn_chain)\n",
    "\n",
    "            # Middle Layer\n",
    "            neurons = feature_map[-1]\n",
    "            cnn_chain = conv_layer_2D(cnn_chain, neurons, strides=1, norm=False)\n",
    "            cnn_chain = conv_layer_2D(cnn_chain, neurons, strides=1, norm=False)\n",
    "            all_middle_chains.append(cnn_chain)\n",
    "          \n",
    "        cnn_chain1 = concatenate(all_middle_chains)\n",
    "        cnn_chain1 = LayerNormalization(epsilon=1e-5)(cnn_chain1)\n",
    "        \n",
    "        for stride, feature_map in self.feature_maps.items():\n",
    "            # Start the CNN Model chain with adding the inputs as first tensor\n",
    "            cnn_chain = cnn_chain1\n",
    "            # Expanding Layers\n",
    "            for i in reversed(range(0, len(feature_map))):\n",
    "                neurons = feature_map[i]\n",
    "                cnn_chain = Conv2DTranspose(neurons, (stride, stride), \n",
    "                                            strides=(stride, stride),\n",
    "                                            padding='same')(cnn_chain)\n",
    "                cnn_chain = SpatialDropout2D(0.5)(cnn_chain)\n",
    "                cnn_chain = concatenate([cnn_chain, contracting_convs[stride][i]], axis=-1)\n",
    "                cnn_chain = conv_layer_2D(cnn_chain, neurons, strides=1)\n",
    "                cnn_chain = conv_layer_2D(cnn_chain, neurons, strides=1)\n",
    "            \n",
    "            all_chains.append(cnn_chain)\n",
    "\n",
    "        # Output Layer\n",
    "        conv_out = Conv2D(n_labels, (1, 1), activation='softmax')(concatenate(all_chains, axis=-1))\n",
    "        # Create Model with associated input and output layers\n",
    "        model = Model(inputs=[inputs], outputs=[conv_out])\n",
    "        # Return model\n",
    "        return model\n",
    "\n",
    "    #---------------------------------------------#\n",
    "    #               Create 3D Model               #\n",
    "    #---------------------------------------------#\n",
    "    def create_model_3D(self, input_shape, n_labels=2):\n",
    "        pass\n",
    "\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#                   Subroutines 2D                    #\n",
    "#-----------------------------------------------------#\n",
    "# Convolution layer\n",
    "def conv_layer_2D(input, neurons, strides=1, norm=True):\n",
    "    conv = Conv2D(neurons, (3, 3), padding='same', strides=strides)(input)\n",
    "    if norm:\n",
    "        conv = tfa.layers.InstanceNormalization(epsilon=1e-5)(conv)\n",
    "\n",
    "    return LeakyReLU(alpha=0.1)(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout, Average, concatenate\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Conv3DTranspose\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Internal libraries/scripts\n",
    "from miscnn.neural_network.architecture.abstract_architecture import Abstract_Architecture\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#           Architecture class: U-Net++               #\n",
    "#-----------------------------------------------------#\n",
    "\"\"\" The Plain variant of the popular U-Net architecture.\n",
    "Methods:\n",
    "    __init__                Object creation function\n",
    "    create_model_2D:        Creating the 2D U-Net plain model using Keras\n",
    "    create_model_3D:        Creating the 3D U-Net plain model using Keras\n",
    "\"\"\"\n",
    "class UNetPlusPlus(Abstract_Architecture):\n",
    "   \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #---------------------------------------------#\n",
    "    #               Create 2D Model               #\n",
    "    #---------------------------------------------#\n",
    "    def create_model_2D(self, input_shape, n_labels=2):\n",
    "        nb_filter = [38,76,152,256,512]\n",
    "        bn_axis = -1\n",
    "        \n",
    "        # Input layer\n",
    "        img_input = Input(input_shape)\n",
    "        \n",
    "        conv1_1 = standard_unit(img_input, stage='11', nb_filter=nb_filter[0])\n",
    "        pool1 = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(conv1_1)\n",
    "\n",
    "        conv2_1 = standard_unit(pool1, stage='21', nb_filter=nb_filter[1])\n",
    "        pool2 = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(conv2_1)\n",
    "\n",
    "        up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up12', padding='same')(conv2_1)\n",
    "        conv1_2 = concatenate([up1_2, conv1_1], name='merge12', axis=bn_axis)\n",
    "        conv1_2 = standard_unit(conv1_2, stage='12', nb_filter=nb_filter[0])\n",
    "\n",
    "        conv3_1 = standard_unit(pool2, stage='31', nb_filter=nb_filter[2])\n",
    "        pool3 = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(conv3_1)\n",
    "\n",
    "        up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up22', padding='same')(conv3_1)\n",
    "        conv2_2 = concatenate([up2_2, conv2_1], name='merge22', axis=bn_axis)\n",
    "        conv2_2 = standard_unit(conv2_2, stage='22', nb_filter=nb_filter[1])\n",
    "\n",
    "        up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up13', padding='same')(conv2_2)\n",
    "        conv1_3 = concatenate([up1_3, conv1_1, conv1_2], name='merge13', axis=bn_axis)\n",
    "        conv1_3 = standard_unit(conv1_3, stage='13', nb_filter=nb_filter[0])\n",
    "\n",
    "        conv4_1 = standard_unit(pool3, stage='41', nb_filter=nb_filter[3])\n",
    "        pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(conv4_1)\n",
    "\n",
    "        up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up32', padding='same')(conv4_1)\n",
    "        conv3_2 = concatenate([up3_2, conv3_1], name='merge32', axis=bn_axis)\n",
    "        conv3_2 = standard_unit(conv3_2, stage='32', nb_filter=nb_filter[2])\n",
    "\n",
    "        up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up23', padding='same')(conv3_2)\n",
    "        conv2_3 = concatenate([up2_3, conv2_1, conv2_2], name='merge23', axis=bn_axis)\n",
    "        conv2_3 = standard_unit(conv2_3, stage='23', nb_filter=nb_filter[1])\n",
    "\n",
    "        up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up14', padding='same')(conv2_3)\n",
    "        conv1_4 = concatenate([up1_4, conv1_1, conv1_2, conv1_3], name='merge14', axis=bn_axis)\n",
    "        conv1_4 = standard_unit(conv1_4, stage='14', nb_filter=nb_filter[0])\n",
    "\n",
    "        conv5_1 = standard_unit(pool4, stage='51', nb_filter=nb_filter[4])\n",
    "\n",
    "        up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n",
    "        conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=bn_axis)\n",
    "        conv4_2 = standard_unit(conv4_2, stage='42', nb_filter=nb_filter[3])\n",
    "\n",
    "        up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n",
    "        conv3_3 = concatenate([up3_3, conv3_1, conv3_2], name='merge33', axis=bn_axis)\n",
    "        conv3_3 = standard_unit(conv3_3, stage='33', nb_filter=nb_filter[2])\n",
    "\n",
    "        up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n",
    "        conv2_4 = concatenate([up2_4, conv2_1, conv2_2, conv2_3], name='merge24', axis=bn_axis)\n",
    "        conv2_4 = standard_unit(conv2_4, stage='24', nb_filter=nb_filter[1])\n",
    "\n",
    "        up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n",
    "        conv1_5 = concatenate([up1_5, conv1_1, conv1_2, conv1_3, conv1_4], name='merge15', axis=bn_axis)\n",
    "        conv1_5 = standard_unit(conv1_5, stage='15', nb_filter=nb_filter[0])\n",
    "\n",
    "        nestnet_output_1 = Conv2D(n_labels, (1, 1), activation='sigmoid', name='output_1', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_2)\n",
    "        nestnet_output_2 = Conv2D(n_labels, (1, 1), activation='sigmoid', name='output_2', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_3)\n",
    "        nestnet_output_3 = Conv2D(n_labels, (1, 1), activation='sigmoid', name='output_3', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_4)\n",
    "        nestnet_output_4 = Conv2D(n_labels, (1, 1), activation='sigmoid', name='output_4', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_5)\n",
    "        nestnet_output = Average()([nestnet_output_1, nestnet_output_2, nestnet_output_3, nestnet_output_4])\n",
    "\n",
    "        return Model(inputs=[img_input], outputs=[nestnet_output])\n",
    "\n",
    "    #---------------------------------------------#\n",
    "    #               Create 3D Model               #\n",
    "    #---------------------------------------------#\n",
    "    def create_model_3D(self, input_shape, n_labels=2):\n",
    "        pass\n",
    "    \n",
    "\n",
    "########################################\n",
    "# 2D Standard\n",
    "########################################\n",
    "\n",
    "def standard_unit(input_tensor, stage, nb_filter, kernel_size=3):\n",
    "    dropout_rate, act = 0.5, \"relu\"\n",
    "    x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, name='conv'+stage+'_1', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(input_tensor)\n",
    "    x = Dropout(dropout_rate, name='dp'+stage+'_1')(x)\n",
    "    x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, name='conv'+stage+'_2', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(x)\n",
    "    x = Dropout(dropout_rate, name='dp'+stage+'_2')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiRes U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, concatenate, BatchNormalization, Activation, add\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Conv3DTranspose\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import ELU, LeakyReLU\n",
    "# Internal libraries/scripts\n",
    "from miscnn.neural_network.architecture.abstract_architecture import Abstract_Architecture\n",
    "\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#         Architecture class: U-Net MultiRes          #\n",
    "#-----------------------------------------------------#\n",
    "\"\"\" The MultiRes variant of the popular U-Net architecture.\n",
    "\n",
    "Methods:\n",
    "    __init__                Object creation function\n",
    "    create_model_2D:        Creating the 2D U-Net standard model using Keras\n",
    "\"\"\"\n",
    "class UNetMultiRes(Abstract_Architecture):\n",
    "    #---------------------------------------------#\n",
    "    #                Initialization               #\n",
    "    #---------------------------------------------#\n",
    "    def __init__(self, activation='sigmoid'):\n",
    "        # Parse parameter\n",
    "        self.activation = activation\n",
    "\n",
    "    #---------------------------------------------#\n",
    "    #               Create 2D Model               #\n",
    "    #---------------------------------------------#\n",
    "    def create_model_2D(self, input_shape, n_labels=2):\n",
    "        # Input layer\n",
    "        inputs = Input(input_shape)\n",
    "        nb_filter = [38,76,152,300,600]\n",
    "\n",
    "        mresblock1 = MultiResBlock_2D(nb_filter[0], inputs)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
    "        mresblock1 = ResPath_2D(nb_filter[0], 4, mresblock1)\n",
    "\n",
    "        mresblock2 = MultiResBlock_2D(nb_filter[1], pool1)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
    "        mresblock2 = ResPath_2D(nb_filter[1], 3, mresblock2)\n",
    "\n",
    "        mresblock3 = MultiResBlock_2D(nb_filter[2], pool2)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
    "        mresblock3 = ResPath_2D(nb_filter[2], 2, mresblock3)\n",
    "\n",
    "        mresblock4 = MultiResBlock_2D(nb_filter[3], pool3)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
    "        mresblock4 = ResPath_2D(nb_filter[3], 1, mresblock4)\n",
    "\n",
    "        mresblock5 = MultiResBlock_2D(nb_filter[4], pool4)\n",
    "\n",
    "        up6 = concatenate([Conv2DTranspose(\n",
    "            nb_filter[3], (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
    "        mresblock6 = MultiResBlock_2D(nb_filter[3], up6)\n",
    "\n",
    "        up7 = concatenate([Conv2DTranspose(\n",
    "            nb_filter[2], (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
    "        mresblock7 = MultiResBlock_2D(nb_filter[2], up7)\n",
    "\n",
    "        up8 = concatenate([Conv2DTranspose(\n",
    "            nb_filter[1], (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
    "        mresblock8 = MultiResBlock_2D(nb_filter[1], up8)\n",
    "\n",
    "        up9 = concatenate([Conv2DTranspose(nb_filter[0], (2, 2), strides=(\n",
    "            2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
    "        mresblock9 = MultiResBlock_2D(nb_filter[0], up9)\n",
    "\n",
    "        conv10 = conv2d_bn(mresblock9, n_labels, 1, 1, activation=self.activation)\n",
    "\n",
    "        model = Model(inputs=[inputs], outputs=[conv10])\n",
    "        return model\n",
    "\n",
    "\n",
    "    #---------------------------------------------#\n",
    "    #               Create 3D Model               #\n",
    "    #---------------------------------------------#\n",
    "    def create_model_3D(self, input_shape, n_labels=2):\n",
    "        pass\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#             Subroutines for 2D version              #\n",
    "#-----------------------------------------------------#\n",
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
    "    '''\n",
    "    2D Convolutional layers\n",
    "\n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer\n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "\n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
    "        activation {str} -- activation function (default: {'relu'})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    if(activation == None):\n",
    "        return x\n",
    "\n",
    "    x = Activation(activation, name=name)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
    "    '''\n",
    "    2D Transposed Convolutional layers\n",
    "\n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer\n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "\n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def MultiResBlock_2D(U, inp, alpha = 1.67):\n",
    "    '''\n",
    "    MultiRes Block\n",
    "\n",
    "    Arguments:\n",
    "        U {int} -- Number of filters in a corrsponding UNet stage\n",
    "        inp {keras layer} -- input layer\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    W = alpha * U\n",
    "\n",
    "    shortcut = inp\n",
    "\n",
    "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
    "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
    "\n",
    "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def ResPath_2D(filters, length, inp):\n",
    "    '''\n",
    "    ResPath\n",
    "\n",
    "    Arguments:\n",
    "        filters {int} -- [description]\n",
    "        length {int} -- length of ResPath\n",
    "        inp {keras layer} -- input layer\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "\n",
    "    shortcut = inp\n",
    "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                         activation=None, padding='same')\n",
    "\n",
    "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    for i in range(length-1):\n",
    "\n",
    "        shortcut = out\n",
    "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                             activation=None, padding='same')\n",
    "\n",
    "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "        out = add([shortcut, out])\n",
    "        out = Activation('relu')(out)\n",
    "        out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIScnn pipeline\n",
    "\n",
    "Now, we can start setup our MIScnn pipeline.  \n",
    "In this scenario, we just want to perform a training and cross-validation process.\n",
    "\n",
    "### Define all preprocessing blocks & training hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Import some libraries\n",
    "import tensorflow as tf\n",
    "from miscnn import Data_IO, Preprocessor, Data_Augmentation, Neural_Network\n",
    "from miscnn.data_loading.interfaces import Image_interface\n",
    "from miscnn.neural_network.metrics import tversky_crossentropy, dice_soft, \\\n",
    "                                          dice_crossentropy, tversky_loss\n",
    "from miscnn.processing.subfunctions import Resize, Normalization\n",
    "\n",
    "# Initialize Data IO & Image Interface\n",
    "interface = Fixed_Image_interface(classes=2, img_type=img_type, img_format=img_format)\n",
    "data_io = Data_IO(interface, path_ds_clean, delete_batchDir=True)\n",
    "\n",
    "# Obtain the sample list\n",
    "sample_list = data_io.get_indiceslist()\n",
    "sample_list.sort()\n",
    "\n",
    "# Create a pixel value normalization Subfunction for z-score scaling\n",
    "sf_norm = Normalization(mode=\"z-score\")\n",
    "# Create a resizing Subfunction to shape 512x512\n",
    "sf_resize = Resize((512, 512))\n",
    "# Assemble Subfunction classes into a list\n",
    "sf = [sf_resize, sf_norm]\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 2\n",
    "initial_learning_rate = 1e-4\n",
    "decay = initial_learning_rate / epochs\n",
    "\n",
    "pp = Preprocessor(data_io, batch_size=batch_size, subfunctions=sf,\n",
    "                  prepare_subfunctions=True, prepare_batches=False,\n",
    "                  data_aug=None, analysis=\"fullimage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define auxiliary Dice-Similarity coefficient function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calc_DSC(truth, pred, classes):\n",
    "    dice_scores = []\n",
    "    # Iterate over each class\n",
    "    for i in range(classes):\n",
    "        try:\n",
    "            gt = np.equal(truth, i)\n",
    "            pd = np.equal(pred, i)\n",
    "            # Calculate Dice\n",
    "            dice = 2*np.logical_and(pd, gt).sum() / (pd.sum() + gt.sum())\n",
    "            dice_scores.append(dice)\n",
    "        except ZeroDivisionError:\n",
    "            dice_scores.append(0.0)\n",
    "    # Return computed Dice Similarity Coefficients\n",
    "    return dice_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start MIScnn pipeline with the complete CV code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "from miscnn.neural_network.architecture.unet.plain import Architecture\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    return lr * 1 / (1 + decay * epoch)\n",
    "\n",
    "all_samples = np.array(sample_list)\n",
    "kfold_splitter = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "dsc_scores = []\n",
    "\n",
    "# Create the Neural Network model\n",
    "model = Neural_Network(preprocessor=pp, loss=tversky_crossentropy,\n",
    "                       metrics=[dice_soft, dice_crossentropy],\n",
    "                       batch_queue_size=10, learninig_rate=initial_learning_rate, \n",
    "                       architecture=UNetMultiRes())\n",
    "print(model.model.summary())\n",
    "\n",
    "for train_index, test_index in kfold_splitter.split(all_samples):\n",
    "    model.reset_weights()\n",
    "    # Define Callbacks\n",
    "    cb_lr = LearningRateScheduler(scheduler, verbose=1)\n",
    "    cb_mc = ModelCheckpoint('cfu_cv.model', monitor='val_dice_soft', save_best_only=True, verbose=3, mode='max')\n",
    "    cb_es = EarlyStopping(monitor='loss', mode='min', min_delta=0.0001, patience=20, verbose=3)\n",
    "    \n",
    "    train_samples, test_samples = all_samples[train_index].tolist(), all_samples[test_index].tolist()\n",
    "    model.evaluate(train_samples, test_samples, epochs=epochs, callbacks=[cb_lr, cb_es, cb_mc])\n",
    "    \n",
    "    model.load('cfu_cv.model', custom_objects={\n",
    "              'dice_soft': dice_soft,\n",
    "              'dice_crossentropy': dice_crossentropy,\n",
    "              'tversky_crossentropy': tversky_crossentropy\n",
    "          })\n",
    "    model.predict(test_samples)\n",
    "    \n",
    "    for sample_test in test_samples:\n",
    "        counts, visited = dict(), set()\n",
    "        cfu_count = sample_test.split('_')[1].lower()\n",
    "\n",
    "        sample_test0 = data_io.sample_loader(sample_test, load_seg=True, load_pred=True)\n",
    "        dsc_scores.append(calc_DSC(sample_test0.seg_data, sample_test0.pred_data, classes=2))\n",
    "        \n",
    "    print(f'Running DSC (CFU): {np.mean([d[1] for d in dsc_scores])}±{np.std([d[1] for d in dsc_scores])}')\n",
    "    print(f'Running DSC (all): {np.mean(dsc_scores)}±{np.std(dsc_scores)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
