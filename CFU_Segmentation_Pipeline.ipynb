{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFU Segmentation Pipeline\n",
    "\n",
    "## File structure setup\n",
    "\n",
    "First we are going to setup our filestructure in order to use the Image IO Interface.  \n",
    "What we want for the Image_interface is something like that:\n",
    "\n",
    "```\n",
    "data/\n",
    "     imgname001/imaging.png\n",
    "                segmentation.png\n",
    "     imgname002/imaging.png\n",
    "                segmentation.png\n",
    "     imgname003/imaging.png\n",
    "                segmentation.png\n",
    "     ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File structure preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(f'GPU device availability: {physical_devices}')\n",
    "\n",
    "# Configure data path for CFU input and output folders\n",
    "path_common = \"{define_your_path_to_cfu_here}\"\n",
    "path_ds_1 = os.path.join(path_common, \"data_hq2\")\n",
    "path_ds_clean = os.path.join(path_common, \"clean_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize file structure\n",
    "if not os.path.exists(path_ds_clean): os.mkdir(path_ds_clean)\n",
    "\n",
    "sample_index = 1\n",
    "# Iterate over both data sets\n",
    "images_gt = glob.glob(f'{path_ds_1}_GT/*imaging_GT_*')\n",
    "images_gt_all = glob.glob(f'{path_ds_1}_GT/*')\n",
    "\n",
    "print(f'Total images: {len(images_gt_all)}')\n",
    "print(f'Selected images: {len(images_gt)}')\n",
    "\n",
    "# Iterate over each sample and transform the data into desired file structure\n",
    "for image_gt in images_gt:\n",
    "    path_parts = os.path.basename(image_gt).split(\"_\")\n",
    "    cfu_part = f'CFU_{path_parts[-1].split(\".\")[0]}'\n",
    "    num_cfu = path_parts[0]\n",
    "    \n",
    "    index = f'CFU_{num_cfu}_{sample_index}'\n",
    "    path_ds_sample_img = os.path.join(path_ds_1, cfu_part, 'imaging.tif')\n",
    "    path_ds_sample_seg = image_gt\n",
    "    # Create sample directory\n",
    "    path_sampleDir = os.path.join(path_ds_clean, index)\n",
    "    if not os.path.exists(path_sampleDir): os.mkdir(path_sampleDir)\n",
    "    # Copy image file into filestructure\n",
    "    path_fs_sample_img = os.path.join(path_sampleDir, \"imaging.tif\")\n",
    "    shutil.copy(path_ds_sample_img, path_fs_sample_img)\n",
    "    # Copy segmentation file into filestructure\n",
    "    path_fs_sample_seg = os.path.join(path_sampleDir, \"segmentation.tif\")\n",
    "    # Load segmentation from file\n",
    "    seg_raw = Image.open(path_ds_sample_seg)\n",
    "    # Convert segmentation from Pillow image to numpy matrix\n",
    "    seg_pil = seg_raw.convert(\"RGB\")\n",
    "    seg_data = np.array(seg_pil)\n",
    "    # Keep only intensity and remove maximum intensitiy range\n",
    "    seg_cond1 = np.where((seg_data[:,:,0] <= 20) & (seg_data[:,:,1] <= 20) & (seg_data[:,:,2] >= 240))\n",
    "    seg_cond0 = np.where((seg_data[:,:,0] > 20) | (seg_data[:,:,1] > 20) | (seg_data[:,:,2] < 240))\n",
    "    seg_data[seg_cond1] = 1\n",
    "    seg_data[seg_cond0] = 0\n",
    "    # Transform numpy array back to a Pillow image & save to disk\n",
    "    seg = Image.fromarray(seg_data)\n",
    "    seg.save(path_fs_sample_seg, format=\"TIFF\")\n",
    "    sample_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a custom architecture\n",
    "### Multi-Path U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Conv3DTranspose\n",
    "from tensorflow.keras.layers import Reshape, Dropout, LeakyReLU, Attention, LayerNormalization\n",
    "# Internal libraries/scripts\n",
    "from miscnn.neural_network.architecture.abstract_architecture import Abstract_Architecture\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#           Architecture class: U-Net Plain           #\n",
    "#-----------------------------------------------------#\n",
    "\"\"\" The Plain variant of the popular U-Net architecture.\n",
    "Methods:\n",
    "    __init__                Object creation function\n",
    "    create_model_2D:        Creating the 2D U-Net plain model using Keras\n",
    "    create_model_3D:        Creating the 3D U-Net plain model using Keras\n",
    "\"\"\"\n",
    "class UNetMultiPath(Abstract_Architecture):\n",
    "    #---------------------------------------------#\n",
    "    #                Initialization               #\n",
    "    #---------------------------------------------#\n",
    "    def __init__(self):\n",
    "        # Create list of filters\n",
    "        self.feature_maps = {\n",
    "            4: [40, 240],\n",
    "            2: [40, 80, 160, 220]\n",
    "        }\n",
    "\n",
    "    #---------------------------------------------#\n",
    "    #               Create 2D Model               #\n",
    "    #---------------------------------------------#\n",
    "    def create_model_2D(self, input_shape, n_labels=2):\n",
    "        # Input layer\n",
    "        inputs = Input(input_shape)\n",
    "        # Cache contracting normalized conv layers\n",
    "        # for later copy & concatenate links\n",
    "        contracting_convs = {c: [] for c in self.feature_maps.keys()}\n",
    "        all_middle_chains = []\n",
    "        all_chains = []\n",
    "        \n",
    "        for stride, feature_map in self.feature_maps.items():\n",
    "            # Start the CNN Model chain with adding the inputs as first tensor\n",
    "            cnn_chain = inputs\n",
    "\n",
    "            # Contracting layers\n",
    "            for i in range(0, len(feature_map)):\n",
    "                neurons = feature_map[i]\n",
    "                cnn_chain = conv_layer_2D(cnn_chain, neurons, strides=1)\n",
    "                cnn_chain = conv_layer_2D(cnn_chain, neurons, strides=1)\n",
    "                cnn_chain = SpatialDropout2D(0.5)(cnn_chain)\n",
    "                contracting_convs[stride].append(cnn_chain)\n",
    "                cnn_chain = MaxPooling2D(pool_size=(stride, stride))(cnn_chain)\n",
    "\n",
    "            # Middle Layer\n",
    "            neurons = feature_map[-1]\n",
    "            cnn_chain = conv_layer_2D(cnn_chain, neurons, strides=1, norm=False)\n",
    "            cnn_chain = conv_layer_2D(cnn_chain, neurons, strides=1, norm=False)\n",
    "            all_middle_chains.append(cnn_chain)\n",
    "          \n",
    "        cnn_chain1 = concatenate(all_middle_chains)\n",
    "        cnn_chain1 = LayerNormalization(epsilon=1e-5)(cnn_chain1)\n",
    "        \n",
    "        for stride, feature_map in self.feature_maps.items():\n",
    "            # Start the CNN Model chain with adding the inputs as first tensor\n",
    "            cnn_chain = cnn_chain1\n",
    "            # Expanding Layers\n",
    "            for i in reversed(range(0, len(feature_map))):\n",
    "                neurons = feature_map[i]\n",
    "                cnn_chain = Conv2DTranspose(neurons, (stride, stride), \n",
    "                                            strides=(stride, stride),\n",
    "                                            padding='same')(cnn_chain)\n",
    "                cnn_chain = SpatialDropout2D(0.5)(cnn_chain)\n",
    "                cnn_chain = concatenate([cnn_chain, contracting_convs[stride][i]], axis=-1)\n",
    "                cnn_chain = conv_layer_2D(cnn_chain, neurons, strides=1)\n",
    "                cnn_chain = conv_layer_2D(cnn_chain, neurons, strides=1)\n",
    "            \n",
    "            all_chains.append(cnn_chain)\n",
    "\n",
    "        # Output Layer\n",
    "        conv_out = Conv2D(n_labels, (1, 1), activation='softmax')(concatenate(all_chains, axis=-1))\n",
    "        # Create Model with associated input and output layers\n",
    "        model = Model(inputs=[inputs], outputs=[conv_out])\n",
    "        # Return model\n",
    "        return model\n",
    "\n",
    "    #---------------------------------------------#\n",
    "    #               Create 3D Model               #\n",
    "    #---------------------------------------------#\n",
    "    def create_model_3D(self, input_shape, n_labels=2):\n",
    "        pass\n",
    "\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#                   Subroutines 2D                    #\n",
    "#-----------------------------------------------------#\n",
    "# Convolution layer\n",
    "def conv_layer_2D(input, neurons, strides=1, norm=True):\n",
    "    conv = Conv2D(neurons, (3, 3), padding='same', strides=strides)(input)\n",
    "    if norm:\n",
    "        conv = tfa.layers.InstanceNormalization(epsilon=1e-5)(conv)\n",
    "\n",
    "    return LeakyReLU(alpha=0.1)(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout, Average, concatenate\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Conv3DTranspose\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Internal libraries/scripts\n",
    "from miscnn.neural_network.architecture.abstract_architecture import Abstract_Architecture\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#           Architecture class: U-Net++               #\n",
    "#-----------------------------------------------------#\n",
    "\"\"\" The Plain variant of the popular U-Net architecture.\n",
    "Methods:\n",
    "    __init__                Object creation function\n",
    "    create_model_2D:        Creating the 2D U-Net plain model using Keras\n",
    "    create_model_3D:        Creating the 3D U-Net plain model using Keras\n",
    "\"\"\"\n",
    "class UNetPlusPlus(Abstract_Architecture):\n",
    "   \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #---------------------------------------------#\n",
    "    #               Create 2D Model               #\n",
    "    #---------------------------------------------#\n",
    "    def create_model_2D(self, input_shape, n_labels=2):\n",
    "        nb_filter = [38,76,152,256,512]\n",
    "        bn_axis = -1\n",
    "        \n",
    "        # Input layer\n",
    "        img_input = Input(input_shape)\n",
    "        \n",
    "        conv1_1 = standard_unit(img_input, stage='11', nb_filter=nb_filter[0])\n",
    "        pool1 = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(conv1_1)\n",
    "\n",
    "        conv2_1 = standard_unit(pool1, stage='21', nb_filter=nb_filter[1])\n",
    "        pool2 = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(conv2_1)\n",
    "\n",
    "        up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up12', padding='same')(conv2_1)\n",
    "        conv1_2 = concatenate([up1_2, conv1_1], name='merge12', axis=bn_axis)\n",
    "        conv1_2 = standard_unit(conv1_2, stage='12', nb_filter=nb_filter[0])\n",
    "\n",
    "        conv3_1 = standard_unit(pool2, stage='31', nb_filter=nb_filter[2])\n",
    "        pool3 = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(conv3_1)\n",
    "\n",
    "        up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up22', padding='same')(conv3_1)\n",
    "        conv2_2 = concatenate([up2_2, conv2_1], name='merge22', axis=bn_axis)\n",
    "        conv2_2 = standard_unit(conv2_2, stage='22', nb_filter=nb_filter[1])\n",
    "\n",
    "        up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up13', padding='same')(conv2_2)\n",
    "        conv1_3 = concatenate([up1_3, conv1_1, conv1_2], name='merge13', axis=bn_axis)\n",
    "        conv1_3 = standard_unit(conv1_3, stage='13', nb_filter=nb_filter[0])\n",
    "\n",
    "        conv4_1 = standard_unit(pool3, stage='41', nb_filter=nb_filter[3])\n",
    "        pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(conv4_1)\n",
    "\n",
    "        up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up32', padding='same')(conv4_1)\n",
    "        conv3_2 = concatenate([up3_2, conv3_1], name='merge32', axis=bn_axis)\n",
    "        conv3_2 = standard_unit(conv3_2, stage='32', nb_filter=nb_filter[2])\n",
    "\n",
    "        up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up23', padding='same')(conv3_2)\n",
    "        conv2_3 = concatenate([up2_3, conv2_1, conv2_2], name='merge23', axis=bn_axis)\n",
    "        conv2_3 = standard_unit(conv2_3, stage='23', nb_filter=nb_filter[1])\n",
    "\n",
    "        up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up14', padding='same')(conv2_3)\n",
    "        conv1_4 = concatenate([up1_4, conv1_1, conv1_2, conv1_3], name='merge14', axis=bn_axis)\n",
    "        conv1_4 = standard_unit(conv1_4, stage='14', nb_filter=nb_filter[0])\n",
    "\n",
    "        conv5_1 = standard_unit(pool4, stage='51', nb_filter=nb_filter[4])\n",
    "\n",
    "        up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n",
    "        conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=bn_axis)\n",
    "        conv4_2 = standard_unit(conv4_2, stage='42', nb_filter=nb_filter[3])\n",
    "\n",
    "        up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n",
    "        conv3_3 = concatenate([up3_3, conv3_1, conv3_2], name='merge33', axis=bn_axis)\n",
    "        conv3_3 = standard_unit(conv3_3, stage='33', nb_filter=nb_filter[2])\n",
    "\n",
    "        up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n",
    "        conv2_4 = concatenate([up2_4, conv2_1, conv2_2, conv2_3], name='merge24', axis=bn_axis)\n",
    "        conv2_4 = standard_unit(conv2_4, stage='24', nb_filter=nb_filter[1])\n",
    "\n",
    "        up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n",
    "        conv1_5 = concatenate([up1_5, conv1_1, conv1_2, conv1_3, conv1_4], name='merge15', axis=bn_axis)\n",
    "        conv1_5 = standard_unit(conv1_5, stage='15', nb_filter=nb_filter[0])\n",
    "\n",
    "        nestnet_output_1 = Conv2D(n_labels, (1, 1), activation='sigmoid', name='output_1', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_2)\n",
    "        nestnet_output_2 = Conv2D(n_labels, (1, 1), activation='sigmoid', name='output_2', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_3)\n",
    "        nestnet_output_3 = Conv2D(n_labels, (1, 1), activation='sigmoid', name='output_3', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_4)\n",
    "        nestnet_output_4 = Conv2D(n_labels, (1, 1), activation='sigmoid', name='output_4', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_5)\n",
    "        nestnet_output = Average()([nestnet_output_1, nestnet_output_2, nestnet_output_3, nestnet_output_4])\n",
    "\n",
    "        return Model(inputs=[img_input], outputs=[nestnet_output])\n",
    "\n",
    "    #---------------------------------------------#\n",
    "    #               Create 3D Model               #\n",
    "    #---------------------------------------------#\n",
    "    def create_model_3D(self, input_shape, n_labels=2):\n",
    "        pass\n",
    "    \n",
    "\n",
    "########################################\n",
    "# 2D Standard\n",
    "########################################\n",
    "\n",
    "def standard_unit(input_tensor, stage, nb_filter, kernel_size=3):\n",
    "    dropout_rate, act = 0.5, \"relu\"\n",
    "    x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, name='conv'+stage+'_1', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(input_tensor)\n",
    "    x = Dropout(dropout_rate, name='dp'+stage+'_1')(x)\n",
    "    x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, name='conv'+stage+'_2', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(x)\n",
    "    x = Dropout(dropout_rate, name='dp'+stage+'_2')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiRes U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, concatenate, BatchNormalization, Activation, add\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Conv3DTranspose\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import ELU, LeakyReLU\n",
    "# Internal libraries/scripts\n",
    "from miscnn.neural_network.architecture.abstract_architecture import Abstract_Architecture\n",
    "\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#         Architecture class: U-Net MultiRes          #\n",
    "#-----------------------------------------------------#\n",
    "\"\"\" The MultiRes variant of the popular U-Net architecture.\n",
    "\n",
    "Methods:\n",
    "    __init__                Object creation function\n",
    "    create_model_2D:        Creating the 2D U-Net standard model using Keras\n",
    "\"\"\"\n",
    "class UNetMultiRes(Abstract_Architecture):\n",
    "    #---------------------------------------------#\n",
    "    #                Initialization               #\n",
    "    #---------------------------------------------#\n",
    "    def __init__(self, activation='sigmoid'):\n",
    "        # Parse parameter\n",
    "        self.activation = activation\n",
    "\n",
    "    #---------------------------------------------#\n",
    "    #               Create 2D Model               #\n",
    "    #---------------------------------------------#\n",
    "    def create_model_2D(self, input_shape, n_labels=2):\n",
    "        # Input layer\n",
    "        inputs = Input(input_shape)\n",
    "        nb_filter = [38,76,152,300,600]\n",
    "\n",
    "        mresblock1 = MultiResBlock_2D(nb_filter[0], inputs)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
    "        mresblock1 = ResPath_2D(nb_filter[0], 4, mresblock1)\n",
    "\n",
    "        mresblock2 = MultiResBlock_2D(nb_filter[1], pool1)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
    "        mresblock2 = ResPath_2D(nb_filter[1], 3, mresblock2)\n",
    "\n",
    "        mresblock3 = MultiResBlock_2D(nb_filter[2], pool2)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
    "        mresblock3 = ResPath_2D(nb_filter[2], 2, mresblock3)\n",
    "\n",
    "        mresblock4 = MultiResBlock_2D(nb_filter[3], pool3)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
    "        mresblock4 = ResPath_2D(nb_filter[3], 1, mresblock4)\n",
    "\n",
    "        mresblock5 = MultiResBlock_2D(nb_filter[4], pool4)\n",
    "\n",
    "        up6 = concatenate([Conv2DTranspose(\n",
    "            nb_filter[3], (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
    "        mresblock6 = MultiResBlock_2D(nb_filter[3], up6)\n",
    "\n",
    "        up7 = concatenate([Conv2DTranspose(\n",
    "            nb_filter[2], (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
    "        mresblock7 = MultiResBlock_2D(nb_filter[2], up7)\n",
    "\n",
    "        up8 = concatenate([Conv2DTranspose(\n",
    "            nb_filter[1], (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
    "        mresblock8 = MultiResBlock_2D(nb_filter[1], up8)\n",
    "\n",
    "        up9 = concatenate([Conv2DTranspose(nb_filter[0], (2, 2), strides=(\n",
    "            2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
    "        mresblock9 = MultiResBlock_2D(nb_filter[0], up9)\n",
    "\n",
    "        conv10 = conv2d_bn(mresblock9, n_labels, 1, 1, activation=self.activation)\n",
    "\n",
    "        model = Model(inputs=[inputs], outputs=[conv10])\n",
    "        return model\n",
    "\n",
    "\n",
    "    #---------------------------------------------#\n",
    "    #               Create 3D Model               #\n",
    "    #---------------------------------------------#\n",
    "    def create_model_3D(self, input_shape, n_labels=2):\n",
    "        pass\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#             Subroutines for 2D version              #\n",
    "#-----------------------------------------------------#\n",
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
    "    '''\n",
    "    2D Convolutional layers\n",
    "\n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer\n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "\n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
    "        activation {str} -- activation function (default: {'relu'})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    if(activation == None):\n",
    "        return x\n",
    "\n",
    "    x = Activation(activation, name=name)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
    "    '''\n",
    "    2D Transposed Convolutional layers\n",
    "\n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer\n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "\n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def MultiResBlock_2D(U, inp, alpha = 1.67):\n",
    "    '''\n",
    "    MultiRes Block\n",
    "\n",
    "    Arguments:\n",
    "        U {int} -- Number of filters in a corrsponding UNet stage\n",
    "        inp {keras layer} -- input layer\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    W = alpha * U\n",
    "\n",
    "    shortcut = inp\n",
    "\n",
    "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
    "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
    "\n",
    "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def ResPath_2D(filters, length, inp):\n",
    "    '''\n",
    "    ResPath\n",
    "\n",
    "    Arguments:\n",
    "        filters {int} -- [description]\n",
    "        length {int} -- length of ResPath\n",
    "        inp {keras layer} -- input layer\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "\n",
    "    shortcut = inp\n",
    "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                         activation=None, padding='same')\n",
    "\n",
    "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    for i in range(length-1):\n",
    "\n",
    "        shortcut = out\n",
    "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                             activation=None, padding='same')\n",
    "\n",
    "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "        out = add([shortcut, out])\n",
    "        out = Activation('relu')(out)\n",
    "        out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIScnn pipeline\n",
    "\n",
    "Now, we can start setup our MIScnn pipeline.  \n",
    "In this scenario, we just want to perform a training and cross-validation process.\n",
    "\n",
    "### Define all preprocessing blocks & training hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Import some libraries\n",
    "import tensorflow as tf\n",
    "from miscnn import Data_IO, Preprocessor, Data_Augmentation, Neural_Network\n",
    "from miscnn.data_loading.interfaces import Image_interface\n",
    "from miscnn.neural_network.metrics import tversky_crossentropy, dice_soft, \\\n",
    "                                          dice_crossentropy, tversky_loss\n",
    "from miscnn.processing.subfunctions import Resize, Normalization\n",
    "\n",
    "# Initialize Data IO & Image Interface\n",
    "interface = Image_interface(classes=2, img_type=\"rgb\", img_format=\"tif\")\n",
    "data_io = Data_IO(interface, path_ds_clean, delete_batchDir=True)\n",
    "\n",
    "# Obtain the sample listdecay = initial_learning_rate / epochs\n",
    "\n",
    "sample_list = data_io.get_indiceslist()\n",
    "sample_list.sort()\n",
    "\n",
    "# Create a pixel value normalization Subfunction for z-score scaling\n",
    "sf_zscore = Normalization(mode=\"z-score\")\n",
    "sf_resize = Resize((512, 512))\n",
    "\n",
    "# Assemble Subfunction classes into a list\n",
    "sf = [sf_resize, sf_zscore]\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 2\n",
    "initial_learning_rate = 1e-4\n",
    "decay = initial_learning_rate / epochs\n",
    "\n",
    "pp = Preprocessor(data_io, batch_size=batch_size, subfunctions=sf,\n",
    "                  prepare_subfunctions=True, prepare_batches=False,\n",
    "                  data_aug=None, analysis=\"fullimage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dynamic programming approach for CFU counting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def count_cfu(seg_data, start=(0, 0), seg_id=None, counts=dict(), visited_pixels=dict(), threshold=0.5):\n",
    "    # approach is based on Dynamic-Programming techniques and memoization\n",
    "    for i in range(start[0], seg_data.shape[0]):\n",
    "        for j in range(start[1], seg_data.shape[1]):\n",
    "            count_cfu_rec(seg_data, i, j, seg_id, counts, visited_pixels, threshold)\n",
    "                \n",
    "def count_cfu_rec(seg_data, i, j, seg_id, counts, visited_pixels, threshold):\n",
    "    if 0 <= i < seg_data.shape[0] and 0 <= j < seg_data.shape[1] and seg_data[i, j] > threshold: \n",
    "        if (i, j) not in visited_pixels:\n",
    "            if not seg_id:\n",
    "                seg_id = (i, j)\n",
    "                counts[seg_id] = set([(i, j)])\n",
    "            elif seg_id in counts:\n",
    "                counts[seg_id].add((i, j))\n",
    "            \n",
    "            if seg_id in counts:\n",
    "                visited_pixels[(i, j)] = seg_id\n",
    "                count_cfu_rec(seg_data, i+1, j, seg_id, counts, visited_pixels, threshold)\n",
    "                count_cfu_rec(seg_data, i, j+1, seg_id, counts, visited_pixels, threshold)\n",
    "                count_cfu_rec(seg_data, i, j-1, seg_id, counts, visited_pixels, threshold)\n",
    "        elif (i, j) in visited_pixels and visited_pixels[(i,j)] != seg_id:\n",
    "            if visited_pixels[(i,j)] in counts and seg_id in counts:\n",
    "                counts[visited_pixels[(i,j)]] |= counts[seg_id]\n",
    "                for c_id in counts[seg_id]:\n",
    "                    visited_pixels[c_id] = visited_pixels[(i,j)]\n",
    "                del counts[seg_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define auxiliary Dice-Similarity coefficient function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calc_DSC(truth, pred, classes):\n",
    "    dice_scores = []\n",
    "    # Iterate over each class\n",
    "    for i in range(classes):\n",
    "        try:\n",
    "            gt = np.equal(truth, i)\n",
    "            pd = np.equal(pred, i)\n",
    "            # Calculate Dice\n",
    "            dice = 2*np.logical_and(pd, gt).sum() / (pd.sum() + gt.sum())\n",
    "            dice_scores.append(dice)\n",
    "        except ZeroDivisionError:\n",
    "            dice_scores.append(0.0)\n",
    "    # Return computed Dice Similarity Coefficients\n",
    "    return dice_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start MIScnn pipeline with the complete CV code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "from miscnn.neural_network.architecture.unet.multiRes import Architecture\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    return lr * 1 / (1 + decay * epoch)\n",
    "\n",
    "def discretize(x):\n",
    "    return 2 if x >= 300 else 1 if x >= 40 else 0\n",
    "\n",
    "cfu_samples = np.array([c for c in sample_list if 'CFU_' in c])\n",
    "kfold_splitter = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "dsc_scores, cfu_cnt_pred, cfu_cnt_gt = [], [], []\n",
    "\n",
    "\n",
    "# Create the Neural Network model\n",
    "model = Neural_Network(preprocessor=pp, loss=tversky_crossentropy,\n",
    "                       metrics=[dice_soft, dice_crossentropy],\n",
    "                       batch_queue_size=10, learninig_rate=initial_learning_rate, \n",
    "                       architecture=UNetMultiPath())\n",
    "print(model.model.summary())\n",
    "\n",
    "for train_index, test_index in kfold_splitter.split(cfu_samples):\n",
    "    model.reset_weights()\n",
    "    # Define Callbacks\n",
    "    cb_lr = LearningRateScheduler(scheduler, verbose=1)\n",
    "    cb_mc = ModelCheckpoint('cfu_cv.model', monitor='val_dice_soft', save_best_only=True, verbose=3, mode='max')\n",
    "    cb_es = EarlyStopping(monitor='loss', mode='min', min_delta=0.0001, patience=20, verbose=3)\n",
    "    \n",
    "    train_samples, test_samples = cfu_samples[train_index].tolist(), cfu_samples[test_index].tolist()\n",
    "    model.evaluate(train_samples, test_samples, epochs=epochs, callbacks=[cb_lr, cb_es, cb_mc])\n",
    "    \n",
    "    model.load('cfu_cv.model', custom_objects={\n",
    "              'dice_soft': dice_soft,\n",
    "              'dice_crossentropy': dice_crossentropy,\n",
    "              'tversky_crossentropy': tversky_crossentropy\n",
    "          })\n",
    "    model.predict(test_samples)\n",
    "    \n",
    "    for sample_test in sorted(test_samples):\n",
    "        sample_test0 = data_io.sample_loader(sample_test, load_seg=True, load_pred=True)\n",
    "        dsc_scores.append(calc_DSC(sample_test0.seg_data, sample_test0.pred_data, classes=2))\n",
    "        threshold = int(np.prod(sample_test0.pred_data.shape) * 0.0000005) \n",
    "\n",
    "        counts, visited = dict(), dict()\n",
    "        count_cfu(sample_test0.pred_data[:,:,0], counts=counts, visited_pixels=visited)\n",
    "        cfu_cnt_pred.append(len([c for c, v in counts.items() if len(v) >= threshold]))\n",
    "        \n",
    "        counts, visited = dict(), dict()\n",
    "        count_cfu(sample_test0.seg_data[:,:,0], counts=counts, visited_pixels=visited)\n",
    "        cfu_cnt_gt.append(len([c for c, v in counts.items() if len(v) >= threshold]))\n",
    "        \n",
    "        if len(counts.items()) >= 300:\n",
    "            pred_data = sample_test0.pred_data\n",
    "            pred_mask = pred_data[:,:,-1].nonzero()\n",
    "            img_data = np.copy(sample_test0.img_data)\n",
    "            for i, j in zip(*pred_mask):\n",
    "                img_data[i, j, :] = [0, 0, 255]\n",
    "            \n",
    "            print(f'CFU dsiplayed: {sample_test}')\n",
    "            display(Image.fromarray(img_data))\n",
    "        \n",
    "    y_true = np.array(cfu_cnt_gt).reshape((-1,1))\n",
    "    y_pred = np.array(cfu_cnt_pred).reshape((-1,1))\n",
    "    \n",
    "    est = KBinsDiscretizer(n_bins=20, encode='ordinal', strategy='uniform')\n",
    "    est.fit(y_true)\n",
    "    print(est.bin_edges_)\n",
    "            \n",
    "    print(f'Running DSC (CFU): {np.mean([d[1] for d in dsc_scores])}±{np.std([d[1] for d in dsc_scores])}')\n",
    "    print(f'Running DSC (all): {np.mean(dsc_scores)}±{np.std(dsc_scores)}')\n",
    "    print(f'Running MAE: {mean_absolute_error(cfu_cnt_gt, cfu_cnt_pred)}')\n",
    "    print(f'Running ACC3: {accuracy_score(list(map(discretize, cfu_cnt_gt)), list(map(discretize, cfu_cnt_pred)))}')\n",
    "    \n",
    "    y_true, y_pred = est.transform(y_true), est.transform(y_pred)\n",
    "    print(f'Running ACC20: {accuracy_score(y_true, y_pred)}')\n",
    "    \n",
    "    for i in range(20):\n",
    "        print(f'Running bin ACC @ {est.bin_edges_[0][i:i+2]}: {accuracy_score(y_true[y_true==i], y_pred[y_true==i])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
